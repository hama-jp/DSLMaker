# Branch & Merge with Sentiment Routing Pattern
# Conditional branching with variable aggregator for merging parallel paths

metadata:
  pattern_id: "pattern_branch_merge_001"
  name: "Branch & Merge Sentiment Routing"
  description: "Branch-merge workflow: Start -> Parameter Extraction (Sentiment) -> Conditional Branch -> Parallel LLM Processing -> Variable Aggregator (Merge) -> Template Format -> End. Ideal for adaptive response generation."
  complexity: "moderate"
  node_count: 8
  use_cases:
    - "Customer service routing"
    - "Sentiment-based response generation"
    - "Multi-path processing with merge"
    - "Adaptive workflow routing"
  tags:
    - "branching"
    - "merging"
    - "sentiment-analysis"
    - "conditional-routing"
    - "variable-aggregator"

workflow:
  version: "0.1"
  graph:
    nodes:
      - id: "start_1"
        type: "start"
        data:
          title: "Customer Input"
          variables:
            - variable: "user_message"
              type: "string"
              label: "User Message"
              required: true
              description: "Customer message to analyze"
          desc: "Accepts customer message"
        position:
          x: 100
          y: 200

      - id: "parameter_extractor_1"
        type: "parameter-extractor"
        data:
          title: "Sentiment Analysis"
          query: "{{#start.user_message#}}"
          model:
            provider: "openai"
            name: "gpt-4"
            completion_params:
              temperature: 0.0
          parameters:
            - name: "sentiment_score"
              type: "number"
              required: true
              description: "Sentiment score (0-1)"
            - name: "sentiment_label"
              type: "string"
              required: true
              description: "Sentiment label (positive/negative/neutral)"
        position:
          x: 350
          y: 200

      - id: "if_else_1"
        type: "if-else"
        data:
          title: "Route by Sentiment"
          logical_operator: "and"
          conditions:
            - variable_selector: ["parameter_extractor", "sentiment_score"]
              comparison_operator: ">"
              value: 0.7
        position:
          x: 600
          y: 200

      - id: "llm_positive"
        type: "llm"
        data:
          title: "Positive Response"
          model:
            provider: "openai"
            name: "gpt-4"
            mode: "chat"
            completion_params:
              temperature: 0.7
          prompt_template:
            - role: "system"
              text: "You are a friendly customer service agent."
            - role: "user"
              text: "Create a positive, helpful response for: {{#start.user_message#}}"
        position:
          x: 850
          y: 120

      - id: "llm_negative"
        type: "llm"
        data:
          title: "Escalation Response"
          model:
            provider: "openai"
            name: "gpt-4"
            mode: "chat"
            completion_params:
              temperature: 0.5
          prompt_template:
            - role: "system"
              text: "You are an empathetic customer service specialist."
            - role: "user"
              text: "Create an empathetic escalation response for: {{#start.user_message#}}"
        position:
          x: 850
          y: 280

      - id: "variable_aggregator_1"
        type: "variable-aggregator"
        data:
          title: "Merge Responses"
          aggregation_mode: "merge"
          output_variables:
            - name: "final_response"
              type: "string"
            - name: "response_type"
              type: "string"
            - name: "confidence"
              type: "number"
        position:
          x: 1100
          y: 200

      - id: "template_transform_1"
        type: "template-transform"
        data:
          title: "Format Output"
          template: |
            Customer Service Response:

            {{#variable_aggregator.final_response#}}

            Response Type: {{#variable_aggregator.response_type#}}
        position:
          x: 1350
          y: 200

      - id: "end_1"
        type: "end"
        data:
          title: "Final Output"
          outputs:
            customer_response: "{{#template_transform.output#}}"
        position:
          x: 1600
          y: 200

    edges:
      - id: "start_1-parameter_extractor_1"
        source: "start_1"
        target: "parameter_extractor_1"
      - id: "parameter_extractor_1-if_else_1"
        source: "parameter_extractor_1"
        target: "if_else_1"
      - id: "if_else_1-llm_positive"
        source: "if_else_1"
        target: "llm_positive"
        source_handle: "true"
      - id: "if_else_1-llm_negative"
        source: "if_else_1"
        target: "llm_negative"
        source_handle: "false"
      - id: "llm_positive-variable_aggregator_1"
        source: "llm_positive"
        target: "variable_aggregator_1"
        target_handle: "input1"
      - id: "llm_negative-variable_aggregator_1"
        source: "llm_negative"
        target: "variable_aggregator_1"
        target_handle: "input2"
      - id: "variable_aggregator_1-template_transform_1"
        source: "variable_aggregator_1"
        target: "template_transform_1"
      - id: "template_transform_1-end_1"
        source: "template_transform_1"
        target: "end_1"